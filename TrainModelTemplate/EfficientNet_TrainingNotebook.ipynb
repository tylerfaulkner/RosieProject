{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# %matplotlib inline\n",
    "# %pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "input_shape = (224,224)\n",
    "train_dir = '/home/nelsonni/data/data/cs3310/Huupe/train_class'\n",
    "test_dir = '/home/nelsonni/data/data/cs3310/Huupe/val_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    zoom_range=0.2,  \n",
    "    rotation_range = 5,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=test_datagen.flow_from_directory(test_dir,\n",
    "                                            class_mode=\"categorical\", \n",
    "                                            target_size=input_shape, \n",
    "                                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37553 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                            class_mode=\"categorical\", \n",
    "                                            target_size=input_shape, \n",
    "                                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your model to use below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB0(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None,\n",
    "    classes=8,\n",
    "    classifier_activation='softmax',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_imgs = 0\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    num_train_imgs += len(files)\n",
    "    \n",
    "num_test_imgs = 0\n",
    "for root, dirs, files in os.walk(test_dir):\n",
    "    num_test_imgs += len(files)\n",
    "    \n",
    "    \n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1173/1173 [==============================] - 580s 494ms/step - loss: 2.3096 - accuracy: 0.1517 - val_loss: 2.1187 - val_accuracy: 0.1587\n",
      "Epoch 2/40\n",
      "1173/1173 [==============================] - 571s 487ms/step - loss: 1.9909 - accuracy: 0.2332 - val_loss: 1.8395 - val_accuracy: 0.2850\n",
      "Epoch 3/40\n",
      "1173/1173 [==============================] - 581s 495ms/step - loss: 1.6021 - accuracy: 0.4019 - val_loss: 1.5388 - val_accuracy: 0.4257\n",
      "Epoch 5/40\n",
      "1173/1173 [==============================] - 579s 494ms/step - loss: 1.4933 - accuracy: 0.4418 - val_loss: 1.5503 - val_accuracy: 0.4257\n",
      "Epoch 6/40\n",
      "1173/1173 [==============================] - 575s 490ms/step - loss: 1.4188 - accuracy: 0.4710 - val_loss: 1.6350 - val_accuracy: 0.4480\n",
      "Epoch 7/40\n",
      "1173/1173 [==============================] - 572s 488ms/step - loss: 1.3848 - accuracy: 0.4852 - val_loss: 1.5667 - val_accuracy: 0.4518\n",
      "Epoch 8/40\n",
      "1173/1173 [==============================] - 574s 489ms/step - loss: 1.3057 - accuracy: 0.5159 - val_loss: 1.6792 - val_accuracy: 0.4650\n",
      "Epoch 10/40\n",
      "1173/1173 [==============================] - 575s 490ms/step - loss: 1.2792 - accuracy: 0.5267 - val_loss: 1.3129 - val_accuracy: 0.5142\n",
      "Epoch 11/40\n",
      "1173/1173 [==============================] - 573s 488ms/step - loss: 1.2561 - accuracy: 0.5324 - val_loss: 1.3052 - val_accuracy: 0.5280\n",
      "Epoch 12/40\n",
      "1173/1173 [==============================] - 577s 492ms/step - loss: 1.2391 - accuracy: 0.5380 - val_loss: 1.3042 - val_accuracy: 0.5138\n",
      "Epoch 13/40\n",
      "1173/1173 [==============================] - 576s 491ms/step - loss: 1.2160 - accuracy: 0.5480 - val_loss: 1.3101 - val_accuracy: 0.5138\n",
      "Epoch 14/40\n",
      "1173/1173 [==============================] - 575s 491ms/step - loss: 1.2033 - accuracy: 0.5518 - val_loss: 1.4150 - val_accuracy: 0.4868\n",
      "Epoch 15/40\n",
      " 158/1173 [===>..........................] - ETA: 7:49 - loss: 1.1874 - accuracy: 0.5574"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=num_train_imgs // 32,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=num_test_imgs // 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ENetB0_40Epochs.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
